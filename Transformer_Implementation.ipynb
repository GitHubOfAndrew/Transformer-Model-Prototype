{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GitHubOfAndrew/Transformer-Model-Prototype/blob/main/Transformer_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOUNT DRIVE\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCaPnCYRhcV7",
        "outputId": "5f033446-3f33-4fe8-9c6b-bc6946a1c5e5"
      },
      "id": "yCaPnCYRhcV7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/NLP Workbooks/Abstractive Summarization/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5EJG8Tyh-lD",
        "outputId": "0b95930c-7979-49fe-c11f-b5e270175d93"
      },
      "id": "M5EJG8Tyh-lD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/NLP Workbooks/Abstractive Summarization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4387fd56",
      "metadata": {
        "id": "4387fd56"
      },
      "source": [
        "# Transformer Implementation\n",
        "\n",
        "Here, we will attempt to implement the Transformer model of natural language processing as indicated in the paper *Attention is All You Need*: https://arxiv.org/pdf/1706.03762.pdf.\n",
        "\n",
        "## Transformer Concepts\n",
        "\n",
        "We have three things to note when we talk about the attention mechanism in Transformers: Query, Key, Value.\n",
        "\n",
        "Although we will not explain in detail what the query and key and value are, it is important to note that they will be utilized in the architecture in a particular way.\n",
        "\n",
        "The primary concept of interest in the transformer model is the idea of **attention**. And more than that, we are interested in **self-attention**. Generally speaking, self-attention determines the impact that a word will have on the sentence. \n",
        "\n",
        "More specifically, the self-attention mechanism works by indicating that for a certain *query* (i.e. a word in our sentence), we compare it to the *keys* (every other token surrounding query), and then we compute the attention between these two quantities. This computed attention is the *value*, from which we will compute the multi-head attention by comparing it with the *keys* again.\n",
        "\n",
        "### Positional Encoding\n",
        "\n",
        "As attention mechanisms have no idea of the ordering of certain tokens in a sentences, we will use a positional encoding to capture the order.\n",
        "\n",
        "$$\\mathrm{PE}_{pos, even\\;dim} = \\sin\\left(pos/10000^{2i/d_{model}}\\right)$$\n",
        "\n",
        "$$\\mathrm{PE}_{pos, odd\\;dim} = \\cos\\left(pos/10000^{2i/d_{model}}\\right)$$\n",
        "\n",
        "### Padding Mask\n",
        "\n",
        "Since the input vector of sequences is fixed in length, we specify a maximum length, and then for any sequences that do not meet the maximum length, we just pad it with zeros.\n",
        "\n",
        "### Look-Ahead Mask\n",
        "\n",
        "A look-ahead mask ensures that target sequences generated in the decoder only have each token contributing to the next token. We incorporate the masked multi-head attention to perform this.\n",
        "\n",
        "### Scaled Dot Product Attention\n",
        "\n",
        "We have the query ($Q$), key ($K$), value ($V$). What we will do is the following:\n",
        "\n",
        "$$A(Q,K,V) = \\mathrm{softmax}\\left(\\frac{Q\\cdot K^{T}}{\\sqrt{d_{k}}}\\right)\\cdot V$$\n",
        "\n",
        "In order to verify that the dimensionality of this is correct, we just look at it.\n",
        "\n",
        "For an input sequence of size $m$, and for words with a max length of $n$,\n",
        "\n",
        "### Multi-Head Attention\n",
        "\n",
        "Here we encapsulate everything we mentioned before. We perform $h$ scaled dot product attention mechanisms, and each will have a query, key, value. For max length of words of $n$, $m$ length sequences, the dimensions of the query, key, value are all computed according to the following:\n",
        "\n",
        "$$\\mathrm{depth} = d_{model} // h$$\n",
        "\n",
        "For each of the $h$ dot product attentions, we have that $d_{model}$ shaped vectors are passed as $h$ separate query, key, value to the attention, and then we concatenate them together after the mechanism to return to the original $d_{model}$ shaped vector.\n",
        "\n",
        "### Regularization and Dense Layers\n",
        "\n",
        "These are typical of neural networks in order to facilitate learning and to prevent overfitting. This is not interesting in practical use, but just helpful. Our transformer architecture visual is in the paper linked above. We will attempt to recreate it here.\n",
        "\n",
        "# Implementation in TensorFlow\n",
        "\n",
        "We will be performing **abstractive summarization** here. This is the more meaningful way to summarize in general as it implies that the model understands the context of the text as opposed to just parsing through it.\n",
        "\n",
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc688e31",
      "metadata": {
        "id": "bc688e31"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import timeit as t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fafaf13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8fafaf13",
        "outputId": "58ab270a-13da-426c-ca29-3a19112f3aba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Headline  \\\n",
              "0      4 ex-bank officials booked for cheating bank o...   \n",
              "1         Supreme Court to go paperless in 6 months: CJI   \n",
              "2      At least 3 killed, 30 injured in blast in Sylh...   \n",
              "3      Why has Reliance been barred from trading in f...   \n",
              "4      Was stopped from entering my own studio at Tim...   \n",
              "...                                                  ...   \n",
              "55099         Sensex loses 400 points to hit 52-week low   \n",
              "55100      China to inject $91 bn into the money markets   \n",
              "55101   Ghulam Ali set to make acting debut in Bollywood   \n",
              "55102       IS acknowledges death of Jihadi John: Report   \n",
              "55103        Cairn to seek $600 mn from India in damages   \n",
              "\n",
              "                                                   Short  \\\n",
              "0      The CBI on Saturday booked four former officia...   \n",
              "1      Chief Justice JS Khehar has said the Supreme C...   \n",
              "2      At least three people were killed, including a...   \n",
              "3      Mukesh Ambani-led Reliance Industries (RIL) wa...   \n",
              "4      TV news anchor Arnab Goswami has said he was t...   \n",
              "...                                                  ...   \n",
              "55099  Tracking weak cues from the Asian markets, the...   \n",
              "55100  Amid growing concerns about China&#39;s econom...   \n",
              "55101  Pakistani Ghazal singer Ghulam Ali will soon m...   \n",
              "55102  The Islamic State (IS) has acknowledged the de...   \n",
              "55103  UK-based oil firm Cairn Energy on Tuesday said...   \n",
              "\n",
              "                      Source      Time  Publish Date  \n",
              "0      The New Indian Express  09:25:00   2017-03-26  \n",
              "1                     Outlook  22:18:00   2017-03-25  \n",
              "2             Hindustan Times  23:39:00   2017-03-25  \n",
              "3                    Livemint  23:08:00   2017-03-25  \n",
              "4                     YouTube  23:24:00   2017-03-25  \n",
              "...                       ...       ...          ...  \n",
              "55099   The Financial Express  10:36:00   2016-01-20  \n",
              "55100                 Reuters  12:06:00   2016-01-20  \n",
              "55101         Hindustan Times  12:10:00   2016-01-20  \n",
              "55102                 YouTube  11:53:00   2016-01-20  \n",
              "55103                PTI News  20:50:00   2016-01-19  \n",
              "\n",
              "[55104 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-201b92ee-f60c-4dbc-8040-bf47027bc083\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "      <th>Source</th>\n",
              "      <th>Time</th>\n",
              "      <th>Publish Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "      <td>The New Indian Express</td>\n",
              "      <td>09:25:00</td>\n",
              "      <td>2017-03-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "      <td>Outlook</td>\n",
              "      <td>22:18:00</td>\n",
              "      <td>2017-03-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "      <td>Hindustan Times</td>\n",
              "      <td>23:39:00</td>\n",
              "      <td>2017-03-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "      <td>Livemint</td>\n",
              "      <td>23:08:00</td>\n",
              "      <td>2017-03-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "      <td>YouTube</td>\n",
              "      <td>23:24:00</td>\n",
              "      <td>2017-03-25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55099</th>\n",
              "      <td>Sensex loses 400 points to hit 52-week low</td>\n",
              "      <td>Tracking weak cues from the Asian markets, the...</td>\n",
              "      <td>The Financial Express</td>\n",
              "      <td>10:36:00</td>\n",
              "      <td>2016-01-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55100</th>\n",
              "      <td>China to inject $91 bn into the money markets</td>\n",
              "      <td>Amid growing concerns about China&amp;#39;s econom...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>12:06:00</td>\n",
              "      <td>2016-01-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55101</th>\n",
              "      <td>Ghulam Ali set to make acting debut in Bollywood</td>\n",
              "      <td>Pakistani Ghazal singer Ghulam Ali will soon m...</td>\n",
              "      <td>Hindustan Times</td>\n",
              "      <td>12:10:00</td>\n",
              "      <td>2016-01-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55102</th>\n",
              "      <td>IS acknowledges death of Jihadi John: Report</td>\n",
              "      <td>The Islamic State (IS) has acknowledged the de...</td>\n",
              "      <td>YouTube</td>\n",
              "      <td>11:53:00</td>\n",
              "      <td>2016-01-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55103</th>\n",
              "      <td>Cairn to seek $600 mn from India in damages</td>\n",
              "      <td>UK-based oil firm Cairn Energy on Tuesday said...</td>\n",
              "      <td>PTI News</td>\n",
              "      <td>20:50:00</td>\n",
              "      <td>2016-01-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55104 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-201b92ee-f60c-4dbc-8040-bf47027bc083')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-201b92ee-f60c-4dbc-8040-bf47027bc083 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-201b92ee-f60c-4dbc-8040-bf47027bc083');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "news_df = pd.read_excel('Inshorts Cleaned Data.xlsx')\n",
        "\n",
        "news_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6ea73f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b6ea73f",
        "outputId": "0a9938a4-bbff-444d-f96e-ef5d096fb625"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Headline', 'Short', 'Source ', 'Time ', 'Publish Date'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "news_df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a19f745e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a19f745e",
        "outputId": "e1fa5a54-cd45-44d4-963b-83681e607721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "news_df = news_df.drop(columns=['Source ', 'Time ', 'Publish Date'])\n",
        "\n",
        "news_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22764391",
      "metadata": {
        "id": "22764391"
      },
      "outputs": [],
      "source": [
        "# split into our input and our label\n",
        "\n",
        "document = news_df['Short']\n",
        "summary = news_df['Headline']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d5bc0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37d5bc0c",
        "outputId": "85065240-38a0-4030-975c-7a28cc2e4b8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "document.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71f651e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71f651e1",
        "outputId": "362b9fb4-854e-4ec5-e587-908149bab360"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104,)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "summary.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c70daa31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c70daa31",
        "outputId": "bcb7bbd4-fd8b-46f8-af0d-afd00a2c9409"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Chief Justice JS Khehar has said the Supreme Court will go paperless in six to seven months in a bid to save funds and make the judiciary eco-friendly. He further said the apex court will collect all the records electronically from the lower courts and the high courts so that there is no need to file hard copies.',\n",
              " 'Supreme Court to go paperless in 6 months: CJI')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "document[1], summary[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba5f8ccd",
      "metadata": {
        "id": "ba5f8ccd"
      },
      "source": [
        "## Preprocess for Input\n",
        "\n",
        "**Remember:** the encoder takes inputs, the decoder takes targets!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "210b01a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "210b01a1",
        "outputId": "6dc4a95e-f73f-40a2-82e8-606d16090551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    <go> 4 ex-bank officials booked for cheating b...\n",
              "1    <go> Supreme Court to go paperless in 6 months...\n",
              "2    <go> At least 3 killed, 30 injured in blast in...\n",
              "3    <go> Why has Reliance been barred from trading...\n",
              "4    <go> Was stopped from entering my own studio a...\n",
              "Name: Headline, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# decoder sequence\n",
        "\n",
        "summary = summary.apply(lambda x: '<go> ' + x + ' <stop>')\n",
        "\n",
        "summary.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "125b5e60",
      "metadata": {
        "id": "125b5e60"
      },
      "source": [
        "### Tokenization\n",
        "\n",
        "Convert our text sequences into vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b79cd1",
      "metadata": {
        "id": "08b79cd1"
      },
      "outputs": [],
      "source": [
        "filter_chars = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "# for unknown tokenizations\n",
        "oov_token = '<unk>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55e3c920",
      "metadata": {
        "id": "55e3c920"
      },
      "outputs": [],
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filter_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccecde69",
      "metadata": {
        "id": "ccecde69"
      },
      "outputs": [],
      "source": [
        "# fit our tokenizers for our respective data\n",
        "\n",
        "document_tokenizer.fit_on_texts(document)\n",
        "\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c813e9",
      "metadata": {
        "id": "e5c813e9"
      },
      "outputs": [],
      "source": [
        "# now convert our input document into sequences\n",
        "# likewise for our target\n",
        "\n",
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30e05ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "b30e05ad",
        "outputId": "71847a3c-a68d-4c88-c7f6-e85680778246"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The CBI on Saturday booked four former officials of Syndicate Bank and six others for cheating, forgery, criminal conspiracy and causing ₹209 crore loss to the state-run bank. The accused had availed home loans and credit from Syndicate Bank on the basis of forged and fabricated documents. These funds were fraudulently transferred to the companies owned by the accused persons.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# compare texts and tokenizations of them\n",
        "\n",
        "document[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd54e220",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd54e220",
        "outputId": "19c7efae-9b5a-4efc-bbca-19299706dfd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2,\n",
              " 1153,\n",
              " 9,\n",
              " 116,\n",
              " 1912,\n",
              " 152,\n",
              " 109,\n",
              " 171,\n",
              " 6,\n",
              " 11881,\n",
              " 180,\n",
              " 8,\n",
              " 209,\n",
              " 326,\n",
              " 12,\n",
              " 3907,\n",
              " 17737,\n",
              " 1467,\n",
              " 3712,\n",
              " 8,\n",
              " 1913,\n",
              " 28258,\n",
              " 55,\n",
              " 735,\n",
              " 3,\n",
              " 2,\n",
              " 61,\n",
              " 295,\n",
              " 180,\n",
              " 2,\n",
              " 236,\n",
              " 35,\n",
              " 11882,\n",
              " 242,\n",
              " 1626,\n",
              " 8,\n",
              " 1809,\n",
              " 20,\n",
              " 11881,\n",
              " 180,\n",
              " 9,\n",
              " 2,\n",
              " 1452,\n",
              " 6,\n",
              " 7463,\n",
              " 8,\n",
              " 13762,\n",
              " 1504,\n",
              " 293,\n",
              " 863,\n",
              " 39,\n",
              " 17738,\n",
              " 3738,\n",
              " 3,\n",
              " 2,\n",
              " 458,\n",
              " 914,\n",
              " 17,\n",
              " 2,\n",
              " 236,\n",
              " 1712]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# the tokenization of the first entry\n",
        "\n",
        "inputs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21a40e0a",
      "metadata": {
        "id": "21a40e0a"
      },
      "source": [
        "To ensure that our tokenization worked, let's just convert the sequence into the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f565a2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3f565a2a",
        "outputId": "75a1af11-839f-4a03-92a0-42d3f16a5102"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the cbi on saturday booked four former officials of syndicate bank and six others for cheating forgery criminal conspiracy and causing ₹209 crore loss to the state run bank the accused had availed home loans and credit from syndicate bank on the basis of forged and fabricated documents these funds were fraudulently transferred to the companies owned by the accused persons'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "document_tokenizer.sequences_to_texts(inputs)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a9fcd39",
      "metadata": {
        "id": "2a9fcd39"
      },
      "source": [
        "We see here that this tokenization worked, and that the tokenizer actually lowercases everything as a default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a7886d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18a7886d",
        "outputId": "7417950c-9f7b-4be8-9174-dc040bc94b01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76362, 29660)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab sizes\n",
        "\n",
        "encoder_vocab_size, decoder_vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953ea7f1",
      "metadata": {
        "id": "953ea7f1"
      },
      "source": [
        "**We will visualize the distribution of word lengths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f67c49",
      "metadata": {
        "id": "93f67c49"
      },
      "outputs": [],
      "source": [
        "doc_lengths = [len(x) for x in document]\n",
        "\n",
        "document_lengths = pd.Series(doc_lengths)\n",
        "\n",
        "sum_lengths = [len(x) for x in summary]\n",
        "\n",
        "summary_lengths = pd.Series(sum_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40166058",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "40166058",
        "outputId": "2cef550b-fcb8-458c-85bd-ce7175c580bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the sequence lengths in document\n",
        "\n",
        "fig1 = plt.figure(figsize=(4,6))\n",
        "\n",
        "axis1 = fig1.add_axes([0.1,0.1,0.9,0.9])\n",
        "\n",
        "axis1.hist(doc_lengths, ec='black', color = 'orange', density=False)\n",
        "\n",
        "axis1.set_title('Distribution of Sequence Lengths in Document')\n",
        "\n",
        "axis1.set_xlabel('Sequence Lengths')\n",
        "\n",
        "axis1.set_ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce2857a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "ce2857a1",
        "outputId": "dd33fa4f-5229-4ace-deed-e040aa90cb72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Frequency')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot the sequence lengths in summary\n",
        "\n",
        "fig2 = plt.figure(figsize=(4,6))\n",
        "\n",
        "axis2 = fig2.add_axes([0.1,0.1,0.9,0.9])\n",
        "\n",
        "axis2.hist(sum_lengths, ec='black', color = 'green', density=False)\n",
        "\n",
        "axis2.set_title('Distribution of Sequence Lengths in Target')\n",
        "\n",
        "axis2.set_xlabel('Sequence Lengths')\n",
        "\n",
        "axis2.set_ylabel('Frequency')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e92dc82f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92dc82f",
        "outputId": "1551ea0b-53dd-4971-e134-e63b7b4a28db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean       368.003049\n",
              "std         26.235510\n",
              "min        280.000000\n",
              "25%        350.000000\n",
              "50%        369.000000\n",
              "75%        387.000000\n",
              "max        469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# descriptive statistics\n",
        "\n",
        "document_lengths.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d721fc76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d721fc76",
        "outputId": "ec48dbd7-0d99-421f-f2b2-d726998869d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean        63.620282\n",
              "std          7.267463\n",
              "min         20.000000\n",
              "25%         59.000000\n",
              "50%         63.000000\n",
              "75%         69.000000\n",
              "max         96.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "summary_lengths.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173d23f3",
      "metadata": {
        "id": "173d23f3"
      },
      "source": [
        "We now have a range to round up to for the padding mask. We will go a little bit past the 75th percentile in order to set the max length of the padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ca5fb8c",
      "metadata": {
        "id": "5ca5fb8c"
      },
      "outputs": [],
      "source": [
        "# encoder_maxlen is the maximum length of the \n",
        "encoder_maxlen, decoder_maxlen = 400, 75"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d6bcc4",
      "metadata": {
        "id": "22d6bcc4"
      },
      "source": [
        "### Padding Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3740cdc",
      "metadata": {
        "id": "b3740cdc"
      },
      "outputs": [],
      "source": [
        "# pad inputs (encoder) and targets (decoder)\n",
        "\n",
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5b6030a",
      "metadata": {
        "id": "d5b6030a"
      },
      "outputs": [],
      "source": [
        "buffer_size = 20000\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185e4de4",
      "metadata": {
        "id": "185e4de4"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(buffer_size).batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "289e4973",
      "metadata": {
        "id": "289e4973"
      },
      "source": [
        "## Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1821c4b9",
      "metadata": {
        "id": "1821c4b9"
      },
      "outputs": [],
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2*(i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e324f94",
      "metadata": {
        "id": "8e324f94"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "    \n",
        "    # apply sin to even indices\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    \n",
        "    # apply cos to odd indices in array\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105c96fb",
      "metadata": {
        "id": "105c96fb"
      },
      "source": [
        "## Masking\n",
        "\n",
        "- Padding mask to mask padded sequences\n",
        "\n",
        "- Lookahead mask for masking future words from contributing to the prediction of current words in self attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e74db728",
      "metadata": {
        "id": "e74db728"
      },
      "outputs": [],
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febca032",
      "metadata": {
        "id": "febca032"
      },
      "outputs": [],
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    return 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c0c02ca",
      "metadata": {
        "id": "5c0c02ca"
      },
      "source": [
        "## Building the Model\n",
        "\n",
        "We will build the attention layers that we indicated above.\n",
        "\n",
        "### Scaled Dot Product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975554a2",
      "metadata": {
        "id": "975554a2"
      },
      "outputs": [],
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "    \n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "    \n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "    \n",
        "    # dot product attention formula\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "    \n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    \n",
        "    return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc3a7ba",
      "metadata": {
        "id": "dbc3a7ba"
      },
      "source": [
        "### Multi-Headed Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8915f8e",
      "metadata": {
        "id": "a8915f8e"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        # the d_model must be divisible by heads\n",
        "        assert d_model % self.num_heads == 0\n",
        "        \n",
        "        self.depth = d_model // self.num_heads\n",
        "        \n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm = [0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        \n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "        \n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "        \n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "        \n",
        "        scaled_attention = tf.transpose(scaled_attention, perm = [0,2,1,3])\n",
        "        \n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "        \n",
        "        return output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d263601d",
      "metadata": {
        "id": "d263601d"
      },
      "source": [
        "## Feedforward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d274da2",
      "metadata": {
        "id": "0d274da2"
      },
      "outputs": [],
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c2dfa8",
      "metadata": {
        "id": "42c2dfa8"
      },
      "source": [
        "## Encoder/Decoder\n",
        "\n",
        "We will build the encoder layers and decoder layers here, then we will build the transformer by just setting the multi-head attention layers, feedforward layers, and encoder/decoder layers in the order that is given in the paper.\n",
        "\n",
        "### Encoder Unit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4558da1",
      "metadata": {
        "id": "f4558da1"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        \n",
        "        # first step of encoder unit\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        \n",
        "        # third step of encoder unit\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "        \n",
        "        # second step of encoder unit\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        # fourth step of encoder unit\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        # dropouts go before each layer normalization step\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x,x,x,mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        \n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "        \n",
        "        return out2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d07797ea",
      "metadata": {
        "id": "d07797ea"
      },
      "source": [
        "### Decoder Unit\n",
        "\n",
        "Recall that this is the one that takes in the target sequences, and gets fed the encoder unit's output midway through."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e901814d",
      "metadata": {
        "id": "e901814d"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        \n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "        \n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "        \n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        \n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x,x,x,look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "        \n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "        \n",
        "        ffn_output = self.ffn(out2)\n",
        "        fnn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "        \n",
        "        return out3, attn_weights_block1, attn_weights_block2\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "481d3d8b",
      "metadata": {
        "id": "481d3d8b"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "This is a layer that consists of multiple encoders. This is the pipeline that includes the embedding layer, positional encoding, and the encoder units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b47788",
      "metadata": {
        "id": "18b47788"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "        \n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        \n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        \n",
        "        x = self.dropout(x, training=training)\n",
        "        \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "            \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1bf429a",
      "metadata": {
        "id": "f1bf429a"
      },
      "source": [
        "## Decoder\n",
        "\n",
        "Decoder consisting of multiple decoder units. In particular, this will be a pipeline containing the embedding, positional encoding, and the decoder units."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "181259b5",
      "metadata": {
        "id": "181259b5"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "        \n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        \n",
        "        x = self.dropout(x, training=training)\n",
        "        \n",
        "        for i in range(num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "            \n",
        "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "            \n",
        "        return x, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a21bf77",
      "metadata": {
        "id": "5a21bf77"
      },
      "source": [
        "## Transformer\n",
        "\n",
        "We will now encapsulate all of the objects we've built into the transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e60668a8",
      "metadata": {
        "id": "e60668a8"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "        \n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "        \n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "        \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "        \n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "        \n",
        "        final_output = self.final_layer(dec_output)\n",
        "        \n",
        "        return final_output, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4070c644",
      "metadata": {
        "id": "4070c644"
      },
      "source": [
        "## Training Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3568f9",
      "metadata": {
        "id": "fe3568f9"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "epochs = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df245de2",
      "metadata": {
        "id": "df245de2"
      },
      "source": [
        "## Optimizer with Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37545ea4",
      "metadata": {
        "id": "37545ea4"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "        \n",
        "        self.warmup_steps = warmup_steps\n",
        "        \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        \n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f0d7600",
      "metadata": {
        "id": "3f0d7600"
      },
      "outputs": [],
      "source": [
        "# NOTE: we can also try a fixed learning rate\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b253dca4",
      "metadata": {
        "id": "b253dca4"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c5974d",
      "metadata": {
        "id": "85c5974d"
      },
      "outputs": [],
      "source": [
        "# loss function\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ba5902",
      "metadata": {
        "id": "85ba5902"
      },
      "outputs": [],
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    \n",
        "    loss_ = loss_fn(real, pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    \n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac9ca22",
      "metadata": {
        "id": "cac9ca22"
      },
      "outputs": [],
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae881ab",
      "metadata": {
        "id": "1ae881ab"
      },
      "source": [
        "## Create Transformer Instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0ec5f40",
      "metadata": {
        "id": "a0ec5f40"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers,\n",
        "    d_model,\n",
        "    num_heads,\n",
        "    dff,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    pe_input = encoder_vocab_size,\n",
        "    pe_target = decoder_vocab_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e80a89f0",
      "metadata": {
        "id": "e80a89f0"
      },
      "source": [
        "### Create Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631bf5f0",
      "metadata": {
        "id": "631bf5f0"
      },
      "outputs": [],
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "    \n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "    \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da9c313e",
      "metadata": {
        "id": "da9c313e"
      },
      "source": [
        "### Checkpoints\n",
        "\n",
        "Store checkpoints to save model at each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e685b31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e685b31",
        "outputId": "682c2da4-650a-4528-8515-7fd54b463eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latest checkpoint restored\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = 'checkpoints'\n",
        "\n",
        "# checkpoint object to store model instances at each epoch\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer,)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print('latest checkpoint restored')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a563564",
      "metadata": {
        "id": "5a563564"
      },
      "source": [
        "## Custom Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15157a64",
      "metadata": {
        "id": "15157a64"
      },
      "outputs": [],
      "source": [
        "# function to run one training loop\n",
        "\n",
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "    \n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "    \n",
        "    # get gradient tape object to perform backpropagation\n",
        "    with tf.GradientTape() as tp:\n",
        "        predictions, _ = transformer(inp, tar_inp, True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "    \n",
        "    # apply gradient descent / optimization\n",
        "    gradients = tp.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "    \n",
        "    # take the mean of all losses\n",
        "    train_loss(loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'We are training for {epochs} epochs.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgk-Ji5cLWqu",
        "outputId": "091dcdcb-2665-45fc-9b31-51ed46e13caf"
      },
      "id": "Hgk-Ji5cLWqu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are training for 25 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8aa78b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8aa78b3",
        "outputId": "c09cbd42-c612-4fa5-a9e1-5f64960b23eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.780 Time taken for this batch 14.214954758000005 secs\n",
            "Epoch 1 Batch 429 Loss 2.770 Time taken for this batch 181.114481155 secs\n",
            "Epoch 1 Batch 858 Loss 2.794 Time taken for this batch 350.683370717 secs\n",
            "Epoch 1 Loss 2.794\n",
            "Time taken for 1 epoch: 351.47584898 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.817 Time taken for this batch 0.490016321999974 secs\n",
            "Epoch 2 Batch 429 Loss 2.675 Time taken for this batch 169.98427917600003 secs\n",
            "Epoch 2 Batch 858 Loss 2.696 Time taken for this batch 339.597651536 secs\n",
            "Epoch 2 Loss 2.696\n",
            "Time taken for 1 epoch: 340.388792948 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 2.684 Time taken for this batch 0.45856736700000056 secs\n",
            "Epoch 3 Batch 429 Loss 2.580 Time taken for this batch 170.04653835200008 secs\n",
            "Epoch 3 Batch 858 Loss 2.612 Time taken for this batch 339.59125223600006 secs\n",
            "Epoch 3 Loss 2.612\n",
            "Time taken for 1 epoch: 340.3852629280001 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 2.357 Time taken for this batch 0.46077263699999094 secs\n",
            "Epoch 4 Batch 429 Loss 2.489 Time taken for this batch 170.05664812600003 secs\n",
            "Epoch 4 Batch 858 Loss 2.530 Time taken for this batch 339.59028167099996 secs\n",
            "Epoch 4 Loss 2.531\n",
            "Time taken for 1 epoch: 340.3851929499999 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.299 Time taken for this batch 0.4589804480001476 secs\n",
            "Epoch 5 Batch 429 Loss 2.412 Time taken for this batch 170.106227601 secs\n",
            "Epoch 5 Batch 858 Loss 2.454 Time taken for this batch 339.7903583110001 secs\n",
            "Saving checkpoint for epoch 5 at checkpoints/ckpt-4\n",
            "Epoch 5 Loss 2.455\n",
            "Time taken for 1 epoch: 342.14517745700005 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.334 Time taken for this batch 0.45641669199994794 secs\n",
            "Epoch 6 Batch 429 Loss 2.342 Time taken for this batch 170.18224334399997 secs\n",
            "Epoch 6 Batch 858 Loss 2.385 Time taken for this batch 339.6361342040002 secs\n",
            "Epoch 6 Loss 2.386\n",
            "Time taken for 1 epoch: 340.4295277120002 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 2.226 Time taken for this batch 0.4612245550001717 secs\n",
            "Epoch 7 Batch 429 Loss 2.284 Time taken for this batch 170.01560076600026 secs\n",
            "Epoch 7 Batch 858 Loss 2.321 Time taken for this batch 339.5022110550003 secs\n",
            "Epoch 7 Loss 2.322\n",
            "Time taken for 1 epoch: 340.29458503000023 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 1.912 Time taken for this batch 0.46062280700016345 secs\n",
            "Epoch 8 Batch 429 Loss 2.214 Time taken for this batch 170.0863877820002 secs\n",
            "Epoch 8 Batch 858 Loss 2.259 Time taken for this batch 339.55633746700005 secs\n",
            "Epoch 8 Loss 2.260\n",
            "Time taken for 1 epoch: 340.35346703799996 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 2.171 Time taken for this batch 0.4632229250000819 secs\n",
            "Epoch 9 Batch 429 Loss 2.154 Time taken for this batch 170.096111931 secs\n",
            "Epoch 9 Batch 858 Loss 2.205 Time taken for this batch 339.7068350290001 secs\n",
            "Epoch 9 Loss 2.205\n",
            "Time taken for 1 epoch: 340.50296586600007 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 2.043 Time taken for this batch 0.45889109500012637 secs\n",
            "Epoch 10 Batch 429 Loss 2.101 Time taken for this batch 169.86760232799998 secs\n",
            "Epoch 10 Batch 858 Loss 2.153 Time taken for this batch 339.496490732 secs\n",
            "Saving checkpoint for epoch 10 at checkpoints/ckpt-5\n",
            "Epoch 10 Loss 2.154\n",
            "Time taken for 1 epoch: 341.3124329530001 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.982 Time taken for this batch 0.4662420879999445 secs\n",
            "Epoch 11 Batch 429 Loss 2.048 Time taken for this batch 170.05439671400018 secs\n",
            "Epoch 11 Batch 858 Loss 2.106 Time taken for this batch 339.59648139699993 secs\n",
            "Epoch 11 Loss 2.107\n",
            "Time taken for 1 epoch: 340.3900628209999 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.962 Time taken for this batch 0.4587136830000418 secs\n",
            "Epoch 12 Batch 429 Loss 2.002 Time taken for this batch 170.02691324199986 secs\n",
            "Epoch 12 Batch 858 Loss 2.058 Time taken for this batch 339.64445192899984 secs\n",
            "Epoch 12 Loss 2.058\n",
            "Time taken for 1 epoch: 340.43796707799993 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.903 Time taken for this batch 0.46058173700021143 secs\n",
            "Epoch 13 Batch 429 Loss 1.962 Time taken for this batch 169.92717618299957 secs\n",
            "Epoch 13 Batch 858 Loss 2.013 Time taken for this batch 339.6335373769998 secs\n",
            "Epoch 13 Loss 2.014\n",
            "Time taken for 1 epoch: 340.4282820320004 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 1.897 Time taken for this batch 0.4639008169997396 secs\n",
            "Epoch 14 Batch 429 Loss 1.919 Time taken for this batch 169.9728986049995 secs\n",
            "Epoch 14 Batch 858 Loss 1.974 Time taken for this batch 339.554691712 secs\n",
            "Epoch 14 Loss 1.975\n",
            "Time taken for 1 epoch: 340.34770732000015 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 1.791 Time taken for this batch 0.4605678630005059 secs\n",
            "Epoch 15 Batch 429 Loss 1.875 Time taken for this batch 169.98498845799986 secs\n",
            "Epoch 15 Batch 858 Loss 1.933 Time taken for this batch 339.5416511530002 secs\n",
            "Saving checkpoint for epoch 15 at checkpoints/ckpt-6\n",
            "Epoch 15 Loss 1.933\n",
            "Time taken for 1 epoch: 341.17872873299984 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 1.773 Time taken for this batch 0.4612792839998292 secs\n",
            "Epoch 16 Batch 429 Loss 1.845 Time taken for this batch 170.1263687849996 secs\n",
            "Epoch 16 Batch 858 Loss 1.898 Time taken for this batch 339.686616725 secs\n",
            "Epoch 16 Loss 1.899\n",
            "Time taken for 1 epoch: 340.47939015500015 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 1.865 Time taken for this batch 0.4599920119999297 secs\n",
            "Epoch 17 Batch 429 Loss 1.810 Time taken for this batch 170.1084520129998 secs\n",
            "Epoch 17 Batch 858 Loss 1.861 Time taken for this batch 339.6263634240004 secs\n",
            "Epoch 17 Loss 1.861\n",
            "Time taken for 1 epoch: 340.4200181670003 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 1.759 Time taken for this batch 0.46207381400017766 secs\n",
            "Epoch 18 Batch 429 Loss 1.766 Time taken for this batch 170.09011666600054 secs\n",
            "Epoch 18 Batch 858 Loss 1.827 Time taken for this batch 339.54786539700035 secs\n",
            "Epoch 18 Loss 1.827\n",
            "Time taken for 1 epoch: 340.33996748500067 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 1.716 Time taken for this batch 0.47067325999978493 secs\n",
            "Epoch 19 Batch 429 Loss 1.737 Time taken for this batch 170.0155956589997 secs\n",
            "Epoch 19 Batch 858 Loss 1.795 Time taken for this batch 339.68083026800014 secs\n",
            "Epoch 19 Loss 1.796\n",
            "Time taken for 1 epoch: 340.4743834130004 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 1.533 Time taken for this batch 0.4586053129996799 secs\n",
            "Epoch 20 Batch 429 Loss 1.704 Time taken for this batch 170.06906921799964 secs\n",
            "Epoch 20 Batch 858 Loss 1.761 Time taken for this batch 339.51178182500007 secs\n",
            "Saving checkpoint for epoch 20 at checkpoints/ckpt-7\n",
            "Epoch 20 Loss 1.761\n",
            "Time taken for 1 epoch: 341.77709834600046 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 1.618 Time taken for this batch 0.4618746480000482 secs\n",
            "Epoch 21 Batch 429 Loss 1.671 Time taken for this batch 170.11176236899973 secs\n",
            "Epoch 21 Batch 858 Loss 1.733 Time taken for this batch 339.49276374500005 secs\n",
            "Epoch 21 Loss 1.734\n",
            "Time taken for 1 epoch: 340.2874348139994 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 1.634 Time taken for this batch 0.46047412299958523 secs\n",
            "Epoch 22 Batch 429 Loss 1.651 Time taken for this batch 170.06513430300038 secs\n",
            "Epoch 22 Batch 858 Loss 1.703 Time taken for this batch 339.54950797699985 secs\n",
            "Epoch 22 Loss 1.703\n",
            "Time taken for 1 epoch: 340.3442554109997 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 1.503 Time taken for this batch 0.4568820249996861 secs\n",
            "Epoch 23 Batch 429 Loss 1.611 Time taken for this batch 170.00637187400025 secs\n",
            "Epoch 23 Batch 858 Loss 1.674 Time taken for this batch 339.5168606289999 secs\n",
            "Epoch 23 Loss 1.674\n",
            "Time taken for 1 epoch: 340.31056387699937 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 1.404 Time taken for this batch 0.46123765500033187 secs\n",
            "Epoch 24 Batch 429 Loss 1.590 Time taken for this batch 170.1110356750005 secs\n",
            "Epoch 24 Batch 858 Loss 1.646 Time taken for this batch 339.6778780499999 secs\n",
            "Epoch 24 Loss 1.647\n",
            "Time taken for 1 epoch: 340.46948159600015 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 1.527 Time taken for this batch 0.4573639450009068 secs\n",
            "Epoch 25 Batch 429 Loss 1.555 Time taken for this batch 170.01033659400127 secs\n",
            "Epoch 25 Batch 858 Loss 1.622 Time taken for this batch 339.4528211700017 secs\n",
            "Saving checkpoint for epoch 25 at checkpoints/ckpt-8\n",
            "Epoch 25 Loss 1.622\n",
            "Time taken for 1 epoch: 341.10262388000046 secs\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    start = t.default_timer()\n",
        "    \n",
        "    train_loss.reset_states()\n",
        "    \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "        \n",
        "        if batch % 429 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.3f} Time taken for this batch {t.default_timer() - start} secs')\n",
        "            \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_savePath = ckpt_manager.save()\n",
        "        print(f'Saving checkpoint for epoch {epoch + 1} at {ckpt_savePath}')\n",
        "        \n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.3f}')\n",
        "    \n",
        "    print(f'Time taken for 1 epoch: {t.default_timer() - start} secs\\n')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing\n",
        "\n",
        "We will now evaluate our trained model."
      ],
      "metadata": {
        "id": "0PpI9nWD5V3w"
      },
      "id": "0PpI9nWD5V3w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d84654",
      "metadata": {
        "id": "f7d84654"
      },
      "outputs": [],
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "    \n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "    \n",
        "    decoder_input = [summary_tokenizer.word_index['<go>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "        \n",
        "        predictions, attention_weights = transformer(encoder_input, output, False, enc_padding_mask, combined_mask, dec_padding_mask)\n",
        "        \n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "        \n",
        "        if predicted_id == summary_tokenizer.word_index['<stop>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "        \n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "        \n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now perform our summarization on a sample news headline."
      ],
      "metadata": {
        "id": "nXkUp8RR5iXJ"
      },
      "id": "nXkUp8RR5iXJ"
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input_document):\n",
        "    \n",
        "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "    \n",
        "    summarized = np.expand_dims(summarized[1:], 0)\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]\n"
      ],
      "metadata": {
        "id": "jj7mGtVH5hLO"
      },
      "id": "jj7mGtVH5hLO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# headline from this article: https://www.nytimes.com/2022/05/01/us/new-mexico-wildfire.html\n",
        "\n",
        "test_doc = 'High winds in northern New Mexico on Sunday once again posed a stiff challenge to crews battling a large wildfire that grew significantly over the weekend.'\n",
        "\n",
        "summarize(test_doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cMSDmngd5nCX",
        "outputId": "568668cd-5935-4c24-a59e-75967541f228"
      },
      "id": "cMSDmngd5nCX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mexico sets up x street ice over 39 batman 39 set'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That was a goofy prediction, let us try a headline that was in our data."
      ],
      "metadata": {
        "id": "73vdXdsX6Tn_"
      },
      "id": "73vdXdsX6Tn_"
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['Headline'][2], news_df['Short'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAZVd4lI6JZZ",
        "outputId": "dfa678a5-438b-412c-f4e1-23549aba20cd"
      },
      "id": "uAZVd4lI6JZZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('At least 3 killed, 30 injured in blast in Sylhet, Bangladesh',\n",
              " 'At least three people were killed, including a policeman, while 30 others were wounded on Saturday evening in two explosions in Sylhet, Bangladesh. The explosions were targetted at people and police officials who were witnessing an over 30-hour-long gunfight between extremists and commandos. Earlier on Friday, a man had blown himself up in front of a checkpoint near Dhaka Airport.')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(news_df['Short'][2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZiAfUL2m6ane",
        "outputId": "66c62dfa-2947-461d-c44a-13402f61b5a6"
      },
      "id": "ZiAfUL2m6ane",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'at least 30 killed as suicide attack across india'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(news_df['Short'][4444])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XcRiE9Al7BC_",
        "outputId": "bb280aba-8da2-4e88-c94b-0d3ac7bf8c1f"
      },
      "id": "XcRiE9Al7BC_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'officials ask for 6k amid cross border defeat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news_df['Headline'][4444]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "npqVVVy57JGI",
        "outputId": "dd84c6f8-a17a-47f9-9143-79100deaba66"
      },
      "id": "npqVVVy57JGI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Stamping of hand baggage stopped at seven Indian airports'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarize('Elon Musk buys Twitter for 40 bn dollars.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fWCp63sR7NQC",
        "outputId": "be42de24-8dc8-47fe-e1f8-19fb9134fcad"
      },
      "id": "fWCp63sR7NQC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'man utd open for 1 mn twitter trip report'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uen50BZ-7VHo"
      },
      "id": "uen50BZ-7VHo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "Transformer Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "22d6bcc4",
        "dbc3a7ba",
        "d07797ea"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}